<!doctype html>
<html lang="en">
    <head>
        <link rel="icon" type="image/x-icon" href="../favicon.ico" />
        <meta charset="utf-8">
        <meta http-equiv="x-ua-compatible" content="ie=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>Particle MCMC methods - Calvin Woo's blog</title>
        <link rel="stylesheet" href="../css/default.css" />
        <link rel="stylesheet" href="../css/syntax.css" />
        <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.0/dist/katex.min.css" integrity="sha384-BdGj8xC2eZkQaxoQ8nSLefg4AV4/AwB3Fj+8SUSo7pnKP6Eoy18liIKTPn9oBYNG" crossorigin="anonymous">
    </head>
    <body>
        <header>
            <div class="logo">
                <a href="../">Calvin's Notebook</a>
            </div>
            <nav>
                <a href="../">Home</a>
                <a href="../about.html">About</a>
                <a href="../contact.html">Contact</a>
                <a href="../archive.html">Archive</a>
            </nav>
        </header>

        <main role="main">
            <h1>Particle MCMC methods</h1>
            <article>
    <section class="header">
        Posted on August 30, 2020
        
            by Calvin
        
    </section>
    <section>
        <p><strong>Note: This blog post is still a rough draft. Read on with caution.</strong></p>
<p>Often in machine learning we want to understand the dynamics of sequences of data, often ordered temporally. In this post we will talk about inference methods for Bayesian dynamic latent variable models, a type of probabilistic graphical model.</p>
<h3 id="importance-sampling">importance sampling</h3>
<p>In a nutshell, Bayesian inference of nonlinear state-space models are analytically intractible, hence the need for approximate methods. To set notation, we will deal with <strong>latent Markov models</strong>, in which sequences of latent states only depend conditionally on the previous state, not the full history of past states before it. We observe a sequence of <strong>observations</strong> <span class="math inline">\(y_t\)</span> for <span class="math inline">\(t=1,...,T\)</span> from the model– this can be something like the total lab test volume in a given time-window, or the number of patients testing positive for an infectious disease (like COVID-19). The main assumption of a latent variable model is that the observations are generated by a set of underlying <strong>latent variables</strong> <span class="math inline">\(x_t\)</span>, which are themselves time-varying.</p>
<p>In the dynamic latent variable models we’re studying, the dynamics in the model are given by the latent state <strong>transitions</strong> <span class="math inline">\(p(x_t|x_{t-1}) = f(x_{t-1}, \theta_\text{trans})\)</span> and <strong>observation probabilities</strong> <span class="math inline">\(p(y_t|x_t) = g(x_t, \theta_\text{obs})\)</span>. Here the tunable parameters are denoted by <span class="math inline">\(\theta=(\theta_\text{obs}, \theta_\text{trans})\)</span>.</p>
<p>Combined we get a full joint distribution</p>
<p><span class="math display">\[ p(x_{0:T}, y_{1:T}, \theta) = \prod_{i=1}^T p(y_t|x_t, \theta_\text{obs})\prod_{i=1}^T p(x_t|x_{t-1}, \theta_\text{trans}) p(x_0|\theta) p(\theta) \]</span></p>
<p><strong>The goal</strong> here is to perform Bayesian inference over the latent variables; that is, we want to compute <span class="math inline">\(p(x_{0:T}|y_{1:T})\)</span>. But as we said before, this is analytically intractible, so the best we can do is approximate it by <em>sampling</em>. However, sampling from <span class="math inline">\(p(x_{0:T}|y_{1:T})\)</span> is also hard!</p>
<p>Instead, we take a cue from Monte Carlo methods and sample instead from a <strong>proposal</strong> distribution <span class="math inline">\(q(x_{0:T}|y_{1:T})\)</span> with larger tails than the model distribution. <strong>Importance sampling</strong> corrects for this bias by scaling the samples from <span class="math inline">\(q\)</span> by an appropriate weight. That is, for a given integrable function <span class="math inline">\(\zeta\)</span>, we compute our desired expectations as</p>
<p><span class="math display">\[ \begin{align} \mathbf{E}_{x\sim p(x_{0:T}|y_{1:T})}[\zeta(x)] &amp;= \mathbf{E}_{x\sim q(x_{0:T}|y_{1:T})}\left[\frac{p(x_{0:T}|y_{1:T})}{q(x_{0:T}|y_{1:T})}\zeta(x)\right] \\ 
&amp;= \mathbf{E}_{x\sim q(x_{0:T}|y_{1:T})}[\omega(x)\zeta(x)] \end{align}
\]</span></p>
<p>where <span class="math inline">\(\omega(x) = \frac{p(x_{0:T}|y_{1:T})}{q(x_{0:T}|y_{1:T})}\)</span>.</p>
<p>What’s the problem here? As we said before, sampling from <span class="math inline">\(p(x_{0:T}|y_{1:T})\)</span> is also hard! Often, it is easier to sample from <span class="math inline">\(p(x_{0:T}, y_{1:T})\)</span>, but then we would have to deal with the normalizing factor <span class="math inline">\(p(y_{1:T})\)</span>. How do we deal with this?</p>
<p>The main trick here is to realize that the normalizing factor is itself an expectation, and hence can be computed via Monte Carlo itself. Indeed,</p>
<p><span class="math display">\[ p(y_{1:T}) = \int_x p(x_{0:T}, y_{1:T}) dx_{0:T} = \int_x \omega(x) q(x_{0:T}|y_{1:T}) dx_{0:T} \]</span></p>
<p>Putting this all together, we get the <strong>self-normalized importance sampler</strong>, described in (pseudo)code:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1-1" title="1"><span class="kw">def</span> normalize(wgts):</a>
<a class="sourceLine" id="cb1-2" title="2">    <span class="cf">return</span> wgts <span class="op">/</span> <span class="bu">sum</span>(wgts)</a>
<a class="sourceLine" id="cb1-3" title="3"></a>
<a class="sourceLine" id="cb1-4" title="4"><span class="kw">def</span> importance(model, proposal, n_samples):</a>
<a class="sourceLine" id="cb1-5" title="5">    q_samples <span class="op">=</span> proposal.sample(n_samples)</a>
<a class="sourceLine" id="cb1-6" title="6">    weights <span class="op">=</span> (model.log_prob(q_samples) <span class="op">-</span> proposal.log_prob(q_samples)).exp()</a>
<a class="sourceLine" id="cb1-7" title="7">    norm_wgts <span class="op">=</span> normalize(weights)</a>
<a class="sourceLine" id="cb1-8" title="8">    <span class="cf">return</span> norm_wgts, q_samples</a></code></pre></div>
<h3 id="particle-filter">particle filter</h3>
<p>The difficulty with importance sampling is choosing a good proposal distribution. If our goal is to compute the marginals <span class="math inline">\(p(x_t|y_{1:t})\)</span>, then it turns out that we don’t need to construct a fancy proposal. It turns out we can reuse the transition probabilities in our model to perform importance sampling. This is called the <strong>particle filter</strong> method.</p>
<p>The method is straightforward: we want to sample from <span class="math inline">\(p(x_t|y_{1:t})\)</span>, so we perform this iteratively, starting with a prior <span class="math inline">\(p(x_0)\)</span>. Now the trick is that our proposal is the transition probability <span class="math inline">\(p(x_1|x_0)\)</span>, which we assume is known. So sampling <span class="math inline">\(\widetilde{x}^{(i)}_1\sim p(x_1|x_0)\)</span> for <span class="math inline">\(i=1..N\)</span> gives a batch of <strong>particles</strong> that we will use to represent our sampled distribution.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb2-1" title="1"><span class="kw">def</span> bootstrap(ys, n_particles<span class="op">=</span><span class="dv">100</span>):</a>
<a class="sourceLine" id="cb2-2" title="2">    n_obs <span class="op">=</span> <span class="bu">len</span>(ys)</a>
<a class="sourceLine" id="cb2-3" title="3">    x <span class="op">=</span> np.zeros(shape<span class="op">=</span>(n_obs, n_particles))</a>
<a class="sourceLine" id="cb2-4" title="4">    <span class="co"># initialize initial predicted states</span></a>
<a class="sourceLine" id="cb2-5" title="5">    x[<span class="dv">0</span>] <span class="op">=</span> x0_init(n_particles)</a>
<a class="sourceLine" id="cb2-6" title="6"></a>
<a class="sourceLine" id="cb2-7" title="7">    <span class="co"># transition to x_1</span></a>
<a class="sourceLine" id="cb2-8" title="8">    x[<span class="dv">1</span>] <span class="op">=</span> transition(x[<span class="dv">0</span>])</a></code></pre></div>
<p>Calculating weights we see that</p>
<p><span class="math display">\[ \widetilde{\omega}_1^{(i)} = \frac{p(\widetilde{x}^{(i)}_1|y_1)}{p(\widetilde{x}^{(i)}_1|x_0)} \propto p(y_1|\widetilde{x}^{(i)}_1) = g(\widetilde{x}^{(i)}_1, \theta_\text{obs}) \]</span></p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb3-1" title="1">    <span class="co"># generate y0 and importance weights</span></a>
<a class="sourceLine" id="cb3-2" title="2">    importance_weights <span class="op">=</span> obs_prob(ys[<span class="dv">1</span>], x[<span class="dv">1</span>])</a>
<a class="sourceLine" id="cb3-3" title="3">    importance_weights <span class="op">=</span> normalize(importance_weights)</a></code></pre></div>
<p>so normalizing <span class="math inline">\(\omega_1^{(i)} = \frac{\widetilde{\omega}_1^{(i)}}{\sum_{j=1}^N \widetilde{\omega}_1^{(j)}}\)</span> gives the importance weights to the sampled particles. That’s the first trick to the particle filter. The second trick is noting that as time goes on, our weights <em>will collapse to zero</em>, and eventually only one particle survives. This is untenable, so we instead <strong>resample</strong> the particles according to their importance weights</p>
<p><span class="math display">\[ a_1^{(i)} \sim \text{Categorical}(\omega^{(j)}_1\text{ for }j=1...N) \]</span></p>
<p>where <span class="math inline">\(a_1\)</span> are the indices of the new resampled particles.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb4-1" title="1">    <span class="co"># resample particles</span></a>
<a class="sourceLine" id="cb4-2" title="2">    resampled_idx <span class="op">=</span> random.choice(<span class="bu">range</span>(n_particles), size<span class="op">=</span>n_particles, p<span class="op">=</span>importance_weights)</a>
<a class="sourceLine" id="cb4-3" title="3">    x[<span class="dv">1</span>] <span class="op">=</span> x[<span class="dv">1</span>, resampled_idx]</a></code></pre></div>
<p>Now we repeat this for each new time-step. We sample <span class="math inline">\(\widetilde{x}^{(i)}_2\sim p(x_2|x^{(i)}_1)\)</span> by <em>propagating</em> each particle, and compute importance weights as normal:</p>
<p><span class="math display">\[ \widetilde{\omega}_2^{(i)} = \frac{p(\widetilde{x}^{(i)}_2|y_2)}{p(\widetilde{x}^{(i)}_2|x^{(i)}_1)} \propto p(y_2|\widetilde{x}^{(i)}_2) = g(\widetilde{x}^{(i)}_2, \theta_\text{obs}) \]</span></p>
<p>We then normalize and resample.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb5-1" title="1">    <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>, n_obs):</a>
<a class="sourceLine" id="cb5-2" title="2">        <span class="co"># transition and compute weights</span></a>
<a class="sourceLine" id="cb5-3" title="3">        x[t] <span class="op">=</span> transition(x[t<span class="dv">-1</span>], p<span class="op">=</span>p)</a>
<a class="sourceLine" id="cb5-4" title="4">        importance_weights <span class="op">=</span> normalize(obs_prob(ys[t], x[t]))</a>
<a class="sourceLine" id="cb5-5" title="5">        <span class="co"># resample particles</span></a>
<a class="sourceLine" id="cb5-6" title="6">        resampled_idx <span class="op">=</span> np.random.choice(<span class="bu">range</span>(n_particles), size<span class="op">=</span>n_particles, p<span class="op">=</span>importance_weights)</a>
<a class="sourceLine" id="cb5-7" title="7">        x[t] <span class="op">=</span> x[t, resampled_idx]</a>
<a class="sourceLine" id="cb5-8" title="8">        </a>
<a class="sourceLine" id="cb5-9" title="9">    <span class="cf">return</span> x</a></code></pre></div>
<p>This is the essence behind a particle filter!</p>
    </section>
</article>

        </main>

        <footer>
            Site proudly generated by
            <a href="http://jaspervdj.be/hakyll">Hakyll</a>
        </footer>
    </body>
</html>
